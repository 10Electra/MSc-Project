{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd52ba20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import torch\n",
    "\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "\n",
    "from superprimitive_fusion.scanner import capture_spherical_scans\n",
    "from superprimitive_fusion.utils import bake_uv_to_vertex_colours\n",
    "from superprimitive_fusion.mesh_fusion_utils import get_mesh_components, show_mesh_boundaries\n",
    "from superprimitive_fusion.mesh_fusion import fuse_meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255c02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device0 = torch.device(\"cuda:0\")\n",
    "\n",
    "torch.autocast(\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "if torch.cuda.get_device_properties(0).major >= 8:\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1789940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam2_checkpoint = \"../models/SAM2/sam2.1_hiera_large.pt\"\n",
    "model_cfg = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
    "\n",
    "sam2 = build_sam2(model_cfg, sam2_checkpoint, device=device0, apply_postprocessing=False)\n",
    "\n",
    "# mask_generator = SAM2AutomaticMaskGenerator(sam2)\n",
    "mask_generator = SAM2AutomaticMaskGenerator(\n",
    "    model=sam2,\n",
    "    points_per_side=64,\n",
    "    points_per_batch=128,\n",
    "    pred_iou_thresh=0.7,\n",
    "    stability_score_thresh=0.92,\n",
    "    stability_score_offset=0.7,\n",
    "    crop_n_layers=1,\n",
    "    box_nms_thresh=0.7,\n",
    "    crop_n_points_downscale_factor=2,\n",
    "    min_mask_region_area=25.0,\n",
    "    use_m2m=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b89b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can place this in a new file or use it as a utility function.\n",
    "\n",
    "import torch\n",
    "from torchvision.ops.boxes import batched_nms, box_area\n",
    "\n",
    "from segment_anything.utils.amg import MaskData, batched_mask_to_box\n",
    "import tool.point_utils as point_utils\n",
    "\n",
    "def infer_sam_masks_batch(model_sam, image, points, logits=True):\n",
    "    # points is same form as keypoints, [N, 2]\n",
    "    # in the range [-1, 1]\n",
    "    device = points.device\n",
    "    num_pts = points.shape[0]\n",
    "\n",
    "    model_sam.set_image(image)\n",
    "    \n",
    "    H, W, _ = image.shape \n",
    "    \n",
    "    H_sam, W_sam = model_sam.transform.get_preprocess_shape(H, W, model_sam.transform.target_length)\n",
    "\n",
    "    points_sam_format = point_utils.denormalise_coordinates(points, (H_sam, W_sam)) \n",
    "    points_sam_format = points_sam_format.flip(-1)\n",
    "\n",
    "    # sam ids for postive / negative ponits. here we use one postive per segment \n",
    "    dummy_ids = torch.ones((num_pts, 1), dtype=torch.int64, device=device)\n",
    "\n",
    "    masks, iou_predictions, lowres =  model_sam.predict_torch(points_sam_format[:, None],\n",
    "                                                              dummy_ids,\n",
    "                                                              multimask_output=True,\n",
    "                                                              return_logits=logits)\n",
    "    \n",
    "    return {'masks': masks, \n",
    "            'iou_pred': iou_predictions,\n",
    "            'lowres': lowres}\n",
    "\n",
    "def predict_sam_segmentation_masks(\n",
    "    sam_model,\n",
    "    image,\n",
    "    sam_config,\n",
    "    keypoints=None,\n",
    "    num_pts=300,\n",
    "    num_pts_active=50,\n",
    "    device=torch.device('cuda:0')\n",
    "):\n",
    "    \"\"\"\n",
    "    Standalone function to predict segmentation masks from an image using SAM.\n",
    "\n",
    "    Args:\n",
    "        sam_model: A SamPredictor instance.\n",
    "        image: Input image as a numpy array (H, W, 3).\n",
    "        sam_config: Dict with SAM config options (see infer_masks).\n",
    "        keypoints: Optional tensor of normalized keypoints [-1, 1], shape (N, 2).\n",
    "        num_pts: Number of random keypoints to sample if keypoints is None.\n",
    "        num_pts_active: Number of active sampling points.\n",
    "        device: Torch device.\n",
    "\n",
    "    Returns:\n",
    "        Dict with masks and related outputs.\n",
    "    \"\"\"\n",
    "    H, W, _ = image.shape\n",
    "\n",
    "    if keypoints is None:\n",
    "        keypoints = (torch.rand(num_pts, 2, device=device) * 2 - 1)\n",
    "\n",
    "    select_smallest = sam_config.get('select_smallest', True)\n",
    "    nms = sam_config.get('nms', True)\n",
    "    box_nms_thresh = sam_config.get('box_nms_thresh', 0.7)\n",
    "    iou_threshold = sam_config.get('iou_threshold', 0.88)\n",
    "    stability_score_thresh = sam_config.get('stability_threshold', 0.95)\n",
    "    filter_edge_keypoints = sam_config.get('filter_edge_points', False)\n",
    "    cut_masks_by_edges = sam_config.get('cut_masks_by_edges', False)\n",
    "    edge_probs_threshold = sam_config.get('edge_probs_threshold', 0.5)\n",
    "    filter_by_box_size = sam_config.get('filter_by_box_size', False)\n",
    "\n",
    "    # 1. Initial mask prediction\n",
    "    masks = infer_sam_masks_batch(sam_model, image, keypoints)\n",
    "    masks = smallest_good_mask_batch(\n",
    "        masks['masks'],\n",
    "        masks['iou_pred'],\n",
    "        iou_threshold=iou_threshold,\n",
    "        stability_score_thresh=stability_score_thresh,\n",
    "        select_smallest=select_smallest\n",
    "    )\n",
    "    masks = MaskData(**masks)\n",
    "    keypoints_filtered = keypoints[masks['keypoints_ids'], ...]\n",
    "\n",
    "    # 2. NMS filtering\n",
    "    if nms:\n",
    "        scores_boxes = 1 / box_area(masks[\"boxes\"])\n",
    "        keep_by_nms = batched_nms(\n",
    "            masks['boxes'].float(),\n",
    "            scores_boxes if filter_by_box_size else masks['iou_preds'],\n",
    "            torch.zeros_like(masks[\"boxes\"][:, 0]),\n",
    "            iou_threshold=box_nms_thresh,\n",
    "        )\n",
    "        masks.filter(keep_by_nms)\n",
    "        keypoints_filtered = keypoints_filtered[keep_by_nms, ...]\n",
    "\n",
    "    # 3. Active sampling for additional masks\n",
    "    coverage_mask = masks['masks'].any(dim=0)\n",
    "    if num_pts_active > 0:\n",
    "        from frontend.segment.mask_generation import active_sample_pos, smallest_good_mask_batch  # local import to avoid circular\n",
    "        sampled_masks = active_sample_pos(coverage_mask[None], num_samples=num_pts_active)\n",
    "        keypoints_active = sampled_masks['normalised_coords'][0]\n",
    "        src_masks_add = infer_sam_masks_batch(sam_model, image, keypoints_active)\n",
    "        src_masks_add = smallest_good_mask_batch(\n",
    "            src_masks_add['masks'],\n",
    "            src_masks_add['iou_pred'],\n",
    "            iou_threshold=iou_threshold,\n",
    "            stability_score_thresh=stability_score_thresh,\n",
    "            select_smallest=select_smallest\n",
    "        )\n",
    "        keypoints_active_filtered = keypoints_active[src_masks_add['keypoints_ids'], ...]\n",
    "        src_masks_add = MaskData(**src_masks_add)\n",
    "        if nms:\n",
    "            add_scores_boxes = 1 / box_area(src_masks_add[\"boxes\"])\n",
    "            keep_by_nms = batched_nms(\n",
    "                src_masks_add['boxes'].float(),\n",
    "                add_scores_boxes if filter_by_box_size else src_masks_add['iou_preds'],\n",
    "                torch.zeros_like(src_masks_add[\"boxes\"][:, 0]),\n",
    "                iou_threshold=box_nms_thresh,\n",
    "            )\n",
    "            src_masks_add.filter(keep_by_nms)\n",
    "            keypoints_active_filtered = keypoints_active_filtered[keep_by_nms, ...]\n",
    "        keypoints_final = torch.cat([keypoints_filtered, keypoints_active_filtered], dim=0)\n",
    "        masks.cat(src_masks_add)\n",
    "    else:\n",
    "        keypoints_final = keypoints_filtered\n",
    "\n",
    "    # 4. Return masks and keypoints\n",
    "    return {\n",
    "        'masks': masks['masks'],\n",
    "        'boxes': masks['boxes'],\n",
    "        'keypoints': keypoints_final,\n",
    "        'iou_preds': masks['iou_preds'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d75a093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = o3d.io.read_triangle_mesh(\"../data/power-drill/textured.obj\", enable_post_processing=True)\n",
    "\n",
    "bake_uv_to_vertex_colours(mesh)\n",
    "\n",
    "mesh.compute_vertex_normals()\n",
    "\n",
    "bb = mesh.get_minimal_oriented_bounding_box()\n",
    "scale = np.mean(bb.get_max_bound())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "974494dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superprimitive_fusion.mesh_fusion_utils import sanitise_mesh, colour_transfer, count_inconsistent_normal_pairs\n",
    "from superprimitive_fusion.debug_utils import debug_mesh\n",
    "import pymeshfix\n",
    "\n",
    "scans = capture_spherical_scans(\n",
    "    mesh=mesh,\n",
    "    mask_generator=None,\n",
    "    num_views=6,\n",
    "    radius=0.3,\n",
    "    width_px=360,\n",
    "    height_px=240,\n",
    "    fov=70,\n",
    "    dropout_rate=0,\n",
    "    depth_error_std=0.0,\n",
    "    translation_error_std=0,\n",
    "    rotation_error_std_degs=0,\n",
    "    k=10,\n",
    "    sampler=\"fibonacci\",\n",
    ")\n",
    "meshes = [scan['mesh'] for scan in scans]\n",
    "\n",
    "# o3d.visualization.draw_geometries(\n",
    "#     meshes,\n",
    "#     window_name=\"Virtual scan\",\n",
    "#     front=[0.3, 1, 0],\n",
    "#     lookat=[0, 0, 0],\n",
    "#     up=[0, 0, 1],\n",
    "#     zoom=0.7,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cde9e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 6\n",
    "repaired = meshes[0]\n",
    "for i in range(1,j):\n",
    "    fused_mesh = fuse_meshes(\n",
    "        repaired,\n",
    "        meshes[i],\n",
    "        h_alpha=3,\n",
    "        trilat_iters=2,\n",
    "        shift_all=False,\n",
    "        fill_holes=False,\n",
    "    )\n",
    "    V0 = np.asarray(fused_mesh.vertices)\n",
    "    F0 = np.asarray(fused_mesh.triangles)\n",
    "    C0 = np.asarray(fused_mesh.vertex_colors)\n",
    "\n",
    "    V0, F0 = sanitise_mesh(V0, F0)\n",
    "\n",
    "    meshfix = pymeshfix.MeshFix(V0, F0)\n",
    "    meshfix.repair(verbose=False, joincomp=False, remove_smallest_components=False)\n",
    "    V1, F1 = meshfix.points, meshfix.faces\n",
    "\n",
    "    C1 = colour_transfer(V0, C0, V1)\n",
    "\n",
    "    repaired = o3d.geometry.TriangleMesh()\n",
    "    repaired.vertices = o3d.utility.Vector3dVector(V1)\n",
    "    repaired.triangles = o3d.utility.Vector3iVector(F1)\n",
    "    repaired.vertex_colors = o3d.utility.Vector3dVector(C1)\n",
    "    repaired.compute_vertex_normals()\n",
    "    # repaired.compute_face_normals()\n",
    "\n",
    "    o3d.visualization.draw_geometries([repaired])\n",
    "\n",
    "\n",
    "o3d.visualization.draw_geometries(\n",
    "    [fused_mesh],\n",
    "    window_name=\"Virtual scan\",\n",
    "    front=[0.3, 1, 0],\n",
    "    lookat=[0, 0, 0],\n",
    "    up=[0, 0, 1],\n",
    "    zoom=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b78d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('start stats')\n",
    "print(\"edge manifold:\", fused_mesh.is_edge_manifold(allow_boundary_edges=True))\n",
    "print(\"vertex manifold:\", fused_mesh.is_vertex_manifold())\n",
    "print(\"self-intersecting:\", fused_mesh.is_self_intersecting())\n",
    "print(\"watertight:\", fused_mesh.is_watertight())\n",
    "\n",
    "import trimesh\n",
    "V = np.asarray(fused_mesh.vertices)\n",
    "F = np.asarray(fused_mesh.triangles)\n",
    "tm = trimesh.Trimesh(vertices=V, faces=F, process=False)\n",
    "print(\"winding consistent:\", tm.is_winding_consistent)\n",
    "print(\"watertight:\", tm.is_watertight)\n",
    "print(\"euler number:\", tm.euler_number)  # sanity: wildly negative often = non-manifold mess\n",
    "print('finish stats')\n",
    "\n",
    "o3d.visualization.draw_geometries(\n",
    "    [fused_mesh],\n",
    "    window_name=\"Virtual scan\",\n",
    "    front=[0.3, 1, 0],\n",
    "    lookat=[0, 0, 0],\n",
    "    up=[0, 0, 1],\n",
    "    zoom=0.7,\n",
    ")\n",
    "\n",
    "new_points = np.asarray(fused_mesh.vertices)\n",
    "fused_mesh_triangles = np.asarray(fused_mesh.triangles)\n",
    "new_colours = np.asarray(fused_mesh.vertex_colors)\n",
    "\n",
    "V0, F0 = sanitise_mesh(new_points, fused_mesh_triangles)\n",
    "C0 = new_colours\n",
    "\n",
    "# meshfix = pymeshfix.MeshFix(V0, F0)\n",
    "# meshfix.repair(verbose=True, joincomp=False, remove_smallest_components=False)\n",
    "# V1, F1 = meshfix.points, meshfix.faces\n",
    "\n",
    "mf = pymeshfix.PyTMesh(True)\n",
    "mf.load_array(V0, F0)\n",
    "# mf.fill_small_boundaries(nbe=5)\n",
    "mf.clean()\n",
    "# mf.join_closest_components()\n",
    "V1, F1 = mf.return_arrays()\n",
    "\n",
    "# mf = pymeshfix.PyTMesh(False)\n",
    "# mf.load_array(V0, F0)\n",
    "\n",
    "# mf.fill_small_boundaries(nbe=100)\n",
    "\n",
    "# V1, F1 = mf.return_arrays()\n",
    "\n",
    "C1 = colour_transfer(V0, C0, V1)\n",
    "\n",
    "repaired = o3d.geometry.TriangleMesh()\n",
    "repaired.vertices = o3d.utility.Vector3dVector(V1)\n",
    "repaired.triangles = o3d.utility.Vector3iVector(F1)\n",
    "repaired.vertex_colors = o3d.utility.Vector3dVector(C1)\n",
    "repaired.compute_vertex_normals()\n",
    "\n",
    "o3d.visualization.draw_geometries([repaired])\n",
    "\n",
    "components = get_mesh_components(fused_mesh, show=True)\n",
    "\n",
    "# n_components = len(components)\n",
    "# tris_added = len(F1) - len(fused_mesh_triangles)\n",
    "# n_inconsistent_pairs_holes = count_inconsistent_normal_pairs(fused_mesh, show=False)\n",
    "# n_inconsistent_pairs_filled = count_inconsistent_normal_pairs(repaired, show=False)\n",
    "# show_mesh_boundaries(fused_mesh, show=True, edges=True)\n",
    "# show_mesh_boundaries(repaired, show=True, edges=True)\n",
    "# show_mesh_boundaries(repaired, show=True, edges=True, base_mesh=fused_mesh)\n",
    "\n",
    "# print(f'{tris_added} triangles were added to fill holes')\n",
    "# print(f'{n_inconsistent_pairs_holes} (w/ holes) is the number of triangle neighbours with inconsistent normals')\n",
    "# print(f'{n_inconsistent_pairs_filled} (holes filled) is the number of triangle neighbours with inconsistent normals')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
