{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7414257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import open3d as o3d\n",
    "from trimesh import Trimesh\n",
    "\n",
    "from moge.model.v2 import MoGeModel\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "\n",
    "from superprimitive_fusion.utils import (get_integer_segments,\n",
    "                   plot_region_numbers,\n",
    "                   triangulate_segments,\n",
    "                   smooth_mask,\n",
    "                   crop_by_SP,\n",
    "                   fill_ring_holes,\n",
    "                   trimesh_to_o3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a795dd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "device0 = torch.device(\"cuda:0\")\n",
    "device1 = torch.device(\"cuda:1\")\n",
    "\n",
    "torch.autocast(\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "if torch.cuda.get_device_properties(0).major >= 8:\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86202de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SAM2\n",
    "sam2_checkpoint = \"../models/SAM2/sam2.1_hiera_tiny.pt\"\n",
    "model_cfg = \"configs/sam2.1/sam2.1_hiera_t.yaml\"\n",
    "\n",
    "sam2 = build_sam2(model_cfg, sam2_checkpoint, device=device0, apply_postprocessing=False)\n",
    "\n",
    "mask_generator = SAM2AutomaticMaskGenerator(sam2)\n",
    "\n",
    "# Load MoGe\n",
    "moge_model = MoGeModel.from_pretrained(\"../models/MoGe/moge-2-vitl-normal.pt\").to(device0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7f8753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../data/mustard360/images/'\n",
    "image_names = os.listdir(image_path)\n",
    "image_names.sort(key=lambda name: int(name.split('_')[1].split('.')[0]))\n",
    "frame_numbers = [int(name.split('_')[1].split('.')[0]) for name in image_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c53fc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "meshes = []\n",
    "idx = [2, 2, 5, 5, 2, 3, 4, 4, 10, 4, 7, 4, 21, 1, 2, 1, 24, 4, 3, 23, 3, 16, 2, 2, 2, 2, 2, 4, 2, 2, 2, 3, 2]\n",
    "for SPID,image_name in zip(idx,image_names):\n",
    "    # Get input image and format for SAM and MoGe\n",
    "    input_image = cv.cvtColor(cv.imread(image_path + image_name), cv.COLOR_BGR2RGB)                       \n",
    "    input_image_moge = torch.tensor(input_image / 255, dtype=torch.float32, device=device0).permute(2, 0, 1)\n",
    "    input_image_sam  = np.array(input_image)\n",
    "\n",
    "    # Run inference for each model\n",
    "    sam_masks = mask_generator.generate(input_image_sam)\n",
    "\n",
    "    moge_output = moge_model.infer(input_image_moge)\n",
    "\n",
    "    # Collapse each binary mask into a single integer mask\n",
    "    segmentation_masks = np.array([mask['segmentation'] for mask in sam_masks])\n",
    "    int_seg = get_integer_segments(segmentation_masks)\n",
    "\n",
    "    # Get array of 3D points from MoGe output\n",
    "    points = moge_output['points'].cpu().numpy()\n",
    "\n",
    "    # Crop the masks, image and points around the desired primitive\n",
    "    int_seg_cropped, img_cropped, points_cropped = crop_by_SP(SPID, int_seg, input_image, points, border=5, make_binary=True)\n",
    "\n",
    "    # Fill holes and smooth the segmentation mask\n",
    "    filled_int_seg = fill_ring_holes(int_seg_cropped, radius=2)\n",
    "    int_seg_smoothed = smooth_mask(filled_int_seg, radius_erode=5, radius_dilate=None)\n",
    "\n",
    "    # Process colours to add to mesh\n",
    "    colours_cropped = np.clip(img_cropped, 0, 255).reshape((-1,3)).astype(np.uint8, casting='unsafe')\n",
    "    alpha_channel = 255*np.ones((np.prod(img_cropped.shape[:2]),1), dtype=np.uint8)\n",
    "    colours_cropped = np.hstack([colours_cropped, alpha_channel])\n",
    "\n",
    "    # Triangulate the pointcloud\n",
    "    verts_cropped = points_cropped.reshape((-1,3))\n",
    "    tris = triangulate_segments(verts_cropped, int_seg_smoothed)\n",
    "    all_tris = [tri for trise in tris for tri in trise]\n",
    "\n",
    "    # Make a mesh\n",
    "    mesh = Trimesh(vertices=verts_cropped, faces=all_tris, vertex_colors=colours_cropped)\n",
    "    meshes.append(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e05cb64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame_number,mesh in zip(frame_numbers, meshes):\n",
    "    pass\n",
    "    # mesh.export(f'../data/mustard360/super-primitives/frame_{frame_number}.ply')\n",
    "    # mesh_o3d = trimesh_to_o3d(mesh)\n",
    "    # o3d.visualization.draw_geometries([mesh_o3d])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62572d58",
   "metadata": {},
   "source": [
    "#### Superprimitive ID of the mustard bottle in each frame\n",
    "idx = [2, 2, 5, 5, 2, 3, 4, 4, 10, 4, 7, 4, 21, 1, 2, 1, 24, 4, 3, 23, 3, 16, 2, 2, 2, 2, 2, 4, 2, 2, 2, 3, 2]\n",
    "\n",
    "for frame numbers\n",
    "\n",
    "frame_numbers = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300, 310, 320]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
