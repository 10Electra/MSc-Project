{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e244b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0772f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _grad_mag(im: np.ndarray) -> np.ndarray:\n",
    "    gx = np.zeros_like(im, dtype=np.float64); gy = np.zeros_like(im, dtype=np.float64)\n",
    "    gx[:, 1:-1] = 0.5*(im[:, 2:] - im[:, :-2])\n",
    "    gy[1:-1, :] = 0.5*(im[2:, :] - im[:-2, :])\n",
    "    return np.sqrt(gx*gx + gy*gy)\n",
    "\n",
    "def _mad_std(x: np.ndarray) -> float:\n",
    "    med = np.median(x)\n",
    "    return 1.4826 * np.median(np.abs(x - med))\n",
    "\n",
    "def calibrate_moge_noise_params(\n",
    "    pairs,  # list of dicts: {'rho_pred','rho_gt','verts_gt','normals_gt','cam_centre','look_dir'}\n",
    "    depth_bins: int = 8,\n",
    "    edge_high_q: float = 0.90,\n",
    "    edge_low_q: float = 0.20,\n",
    "    grazing_front_thresh: float = 0.95,\n",
    "):\n",
    "    r_all = []; dtil_all = []; g_all = []; costh_all = []; valid_counts = 0\n",
    "    lf_stds = []\n",
    "\n",
    "    for P in pairs:\n",
    "        rho_pred = P['rho_pred']; rho_gt = P['rho_gt']\n",
    "        Vgt = P['verts_gt']; Ngt = P['normals_gt']\n",
    "        C = np.asarray(P['cam_centre']).reshape(1,3).astype(np.float64)\n",
    "        L = np.asarray(P['look_dir']).reshape(3).astype(np.float64); L /= (np.linalg.norm(L)+1e-12)\n",
    "\n",
    "        assert rho_pred.shape == rho_gt.shape == Ngt.shape[:2] == Vgt.shape[:2]\n",
    "        H, W = rho_gt.shape\n",
    "\n",
    "        valid = np.isfinite(rho_pred) & np.isfinite(rho_gt) & (rho_gt > 0)\n",
    "        if not np.any(valid): continue\n",
    "        valid_counts += int(valid.sum())\n",
    "\n",
    "        # log residuals\n",
    "        z_pred = np.log(np.maximum(rho_pred, 1e-12))\n",
    "        z_gt   = np.log(np.maximum(rho_gt,   1e-12))\n",
    "        r = (z_pred - z_gt)[valid]\n",
    "\n",
    "        # normalised depth\n",
    "        rho = rho_gt[valid]\n",
    "        rho_med = np.median(rho)\n",
    "        dtil = rho / max(rho_med, 1e-12)\n",
    "\n",
    "        # depth gradient\n",
    "        g = _grad_mag(rho_gt)[valid]\n",
    "\n",
    "        # grazing cos(theta) from GT normals and viewing rays\n",
    "        R = (Vgt - C).reshape(-1,3)\n",
    "        ray = R / (np.linalg.norm(R, axis=1, keepdims=True) + 1e-12)\n",
    "        ray = ray.reshape(H, W, 3)\n",
    "        cos_th = np.abs(np.sum(Ngt * (-ray), axis=2))[valid]\n",
    "\n",
    "        r_all.append(r); dtil_all.append(dtil); g_all.append(g); costh_all.append(cos_th)\n",
    "\n",
    "        # low-frequency std via blurred residuals (ignore NaNs crudely)\n",
    "        rmap = np.full_like(rho_gt, np.nan, dtype=np.float64); rmap[valid] = r\n",
    "        m = np.isfinite(rmap); tmp = np.where(m, rmap, 0.0)\n",
    "        k = 9; pad = k//2\n",
    "        csum = np.pad(tmp, pad, mode='edge').cumsum(0).cumsum(1)\n",
    "        csum_m = np.pad(m.astype(np.float64), pad, mode='edge').cumsum(0).cumsum(1)\n",
    "        num = (csum[k:,k:] - csum[:-k,k:] - csum[k:,:-k] + csum[:-k,:-k])\n",
    "        den = (csum_m[k:,k:] - csum_m[:-k,k:] - csum_m[k:,:-k] + csum_m[:-k,:-k])\n",
    "        blur = np.where(den>0, num/den, 0.0)\n",
    "        lf_stds.append(np.nanstd(blur[m]))\n",
    "\n",
    "    if valid_counts == 0:\n",
    "        raise ValueError(\"No valid pixels across provided pairs.\")\n",
    "\n",
    "    r_all = np.concatenate(r_all); dtil_all = np.concatenate(dtil_all)\n",
    "    g_all = np.concatenate(g_all); costh_all = np.concatenate(costh_all)\n",
    "\n",
    "    # Robust scaling for edge normalisation\n",
    "    g90 = np.quantile(g_all, edge_high_q)\n",
    "    g_norm = np.clip(g_all / (g90 + 1e-12), 0.0, 1.0)\n",
    "\n",
    "    # Fit a0,a1 on easy pixels (low-edge & near-front)\n",
    "    easy = (g_norm < edge_low_q) & (costh_all > grazing_front_thresh)\n",
    "    if not np.any(easy):  # fallback: lowest 30% edges\n",
    "        easy = g_norm < 0.30\n",
    "    q = np.linspace(0.0, 1.0, depth_bins+1)\n",
    "    qs = np.quantile(dtil_all[easy], q)\n",
    "    d_centres = []; mad_vals = []\n",
    "    for i in range(depth_bins):\n",
    "        m = easy & (dtil_all >= qs[i]) & (dtil_all < qs[i+1])\n",
    "        if not np.any(m): continue\n",
    "        d_centres.append(np.median(dtil_all[m]))\n",
    "        mad_vals.append(_mad_std(r_all[m]))\n",
    "    A = np.c_[np.ones(len(d_centres)), np.array(d_centres)]\n",
    "    sol, *_ = np.linalg.lstsq(A, np.array(mad_vals), rcond=None)\n",
    "    a0 = float(max(sol[0], 1e-6)); a1 = float(max(sol[1], 0.0))\n",
    "\n",
    "    # Edge multiplier via MAD ratio (high-edge vs low-edge)\n",
    "    low_edge = g_norm < edge_low_q\n",
    "    high_edge = g_norm >= 0.9\n",
    "    m_low = _mad_std(r_all[low_edge]) if np.any(low_edge) else np.nan\n",
    "    m_high= _mad_std(r_all[high_edge]) if np.any(high_edge) else np.nan\n",
    "    if np.isfinite(m_low) and np.isfinite(m_high) and m_low > 1e-12:\n",
    "        edge_mult = float(np.clip(m_high / m_low, 1.5, 5.0))\n",
    "    else:\n",
    "        edge_mult = 3.0\n",
    "\n",
    "    # Grazing lambda from low-edge bins vs (1 - cos(theta))\n",
    "    mask_g = low_edge\n",
    "    x = (1.0 - np.clip(costh_all[mask_g], 0.0, 1.0))\n",
    "    # predicted base sigma without edge/grazing\n",
    "    sigma_base = a0 + a1 * dtil_all[mask_g]\n",
    "    sigma_base = np.maximum(sigma_base, 1e-6)\n",
    "    # Bin by x and compute MAD ratios\n",
    "    xb = np.quantile(x, [0.0, 0.25, 0.5, 0.75, 1.0])\n",
    "    Xc, Y = [], []\n",
    "    for i in range(len(xb)-1):\n",
    "        sel = (x >= xb[i]) & (x < xb[i+1])\n",
    "        if not np.any(sel): continue\n",
    "        mad_r = _mad_std(r_all[mask_g][sel])\n",
    "        med_sb= np.median(sigma_base[sel])\n",
    "        if med_sb <= 0: continue\n",
    "        y = mad_r / med_sb\n",
    "        Xc.append(np.median(x[sel])); Y.append(y)\n",
    "    # Fit y =~ 1 + lambda x, clamp\n",
    "    if len(Xc) >= 2:\n",
    "        A = np.c_[np.ones(len(Xc)), np.array(Xc)]\n",
    "        b = np.array(Y)\n",
    "        sol, *_ = np.linalg.lstsq(A, b, rcond=None)\n",
    "        grazing_lambda = float(np.clip(sol[1], 0.0, 5.0))\n",
    "    else:\n",
    "        grazing_lambda = 1.0\n",
    "\n",
    "    # Low-frequency std\n",
    "    corr_std_log = float(np.median(lf_stds)) if lf_stds else 0.015\n",
    "\n",
    "    # Global inflation corr_inflate for ~68% coverage (one-step scaling)\n",
    "    # Predicted sigma without corr-field: (a0+a1*dtil)*f_edge*f_graz\n",
    "    f_edge = 1.0 + (edge_mult - 1.0) * g_norm\n",
    "    f_graz = 1.0 + grazing_lambda * (1.0 - np.clip(costh_all, 0.0, 1.0))\n",
    "    f_graz = np.minimum(f_graz, 3.0)\n",
    "    sigma_pred = (a0 + a1 * dtil_all) * f_edge * f_graz\n",
    "    sigma_pred = np.maximum(sigma_pred, 1e-6)\n",
    "    cover = float(np.mean(np.abs(r_all) <= sigma_pred))\n",
    "    corr_inflate = float(np.clip((0.68 / max(cover, 1e-3)), 1.0, 2.5))\n",
    "\n",
    "    return {\n",
    "        \"a0\": a0, \"a1\": a1,\n",
    "        \"edge_mult\": edge_mult,\n",
    "        \"grazing_lambda\": grazing_lambda,\n",
    "        \"corr_std_log\": corr_std_log,\n",
    "        \"corr_inflate\": corr_inflate,\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
